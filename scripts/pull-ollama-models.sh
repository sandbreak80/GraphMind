#!/bin/bash

# GraphMind Ollama Models Auto-Pull Script
# This script automatically pulls all required models for GraphMind

echo "ðŸ§  GraphMind Ollama Models Auto-Pull Starting..."

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
until curl -s http://localhost:11434/api/tags > /dev/null 2>&1; do
    echo "   Waiting for Ollama service..."
    sleep 5
done

echo "âœ… Ollama is ready, starting model downloads..."

# Default chat / research
echo "ðŸ“¥ Pulling llama3.1:8b-instruct (default chat/research)..."
ollama pull llama3.1:8b-instruct

# Reasoning / tough analysis
echo "ðŸ“¥ Pulling deepseek-r1:14b (reasoning/tough analysis)..."
ollama pull deepseek-r1:14b

echo "ðŸ“¥ Pulling deepseek-r1:7b (reasoning/tough analysis)..."
ollama pull deepseek-r1:7b

# Long-context / all-in-one deep dives
echo "ðŸ“¥ Pulling qwen2.5:14b (long-context/deep dives)..."
ollama pull qwen2.5:14b

echo "ðŸ“¥ Pulling qwen2.5:32b (long-context/deep dives)..."
ollama pull qwen2.5:32b

# Coding / tool logic
echo "ðŸ“¥ Pulling qwen2.5-coder:7b (coding/tool logic)..."
ollama pull qwen2.5-coder:7b

echo "ðŸ“¥ Pulling qwen2.5-coder:14b (coding/tool logic)..."
ollama pull qwen2.5-coder:14b

# Small model (prompt uplift, planner, classifiers)
echo "ðŸ“¥ Pulling llama3.2:3b-instruct (small model/prompt uplift)..."
ollama pull llama3.2:3b-instruct

echo "ðŸ“¥ Pulling phi3:mini (small model/planner/classifiers)..."
ollama pull phi3:mini

# Vision (optional)
echo "ðŸ“¥ Pulling qwen3-vl (vision model)..."
ollama pull qwen3-vl

echo "ðŸŽ‰ All GraphMind models downloaded successfully!"
echo ""
echo "ðŸ“‹ Available models:"
ollama list
