services:
  rag-service:
    build: .
    container_name: emini-rag
    ports:
      - "8001:8000"
    volumes:
      # Mount documents directory - update DOCUMENTS_DIR in .env file
      - ${DOCUMENTS_DIR:-./documents}:/workspace/pdfs:ro
      - chroma-data:/workspace/chroma_db
      - ${OUTPUT_DIR:-./outputs}:/workspace/outputs
    environment:
      # LLM Configuration
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL=llama3.1
      
      # Video Processing
      - WHISPER_MODEL_SIZE=base              # tiny, base, small, medium, large
      - VIDEO_FRAME_INTERVAL=30              # Extract keyframe every N seconds
      
      # Retrieval Configuration (Optimized for 90%+ Recall)
      - BM25_TOP_K=200                       # Cast wider net for keyword search
      - EMBEDDING_TOP_K=100                  # Increased from 20 for high recall
      - RERANK_TOP_K=10                      # More final results
      - MIN_SIMILARITY_THRESHOLD=0.3         # Filter low-relevance results
      
      # GPU
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    extra_hosts:
      - "host.docker.internal:host-gateway"

volumes:
  chroma-data:
    driver: local
